{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76519e24-f422-4a8f-af5f-c4423259bde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, logging, os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b40605e-661a-40d3-ab88-4bb9b02a8508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4726b1ca115410d9f5f522f1c00a8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf, .docx, .png, .txt, .jpg, .jpeg', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.pdf, .docx, .png, .txt, .jpg, .jpeg',\n",
    "    multiple=True\n",
    ")\n",
    "\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d14a9466-b2d5-4c3e-8713-6ee6a4c57593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "CV_FOLDER = \"CVS/Resume\"\n",
    "HASH_FOLDER = 'CVS'\n",
    "os.makedirs(CV_FOLDER, exist_ok=True)\n",
    "\n",
    "HASH_FILE = os.path.join(HASH_FOLDER, \"file_hashes.txt\")\n",
    "\n",
    "# Load existing hashes if available\n",
    "if os.path.exists(HASH_FILE):\n",
    "    with open(HASH_FILE, \"r\") as f:\n",
    "        existing_hashes = set(line.strip() for line in f)\n",
    "else:\n",
    "    existing_hashes = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "579e4097-5098-46a6-a856-ac14e4b9cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for uploaded_file in uploader.value:\n",
    "    file_hash = hashlib.sha256(uploaded_file.content).hexdigest()\n",
    "    if file_hash in existing_hashes:\n",
    "        print(f\"Skipped duplicate: {uploaded_file.name}\")\n",
    "        continue \n",
    "        \n",
    "    with open(HASH_FILE, 'a') as f:\n",
    "        f.write(file_hash+'\\n')\n",
    "    existing_hashes.add(file_hash)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
    "    unique_filename = f\"{timestamp}_{uploaded_file.name}\"\n",
    "    path = os.path.join(CV_FOLDER, unique_filename)\n",
    "    \n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(uploaded_file.content)\n",
    "    print(f\"Saved: {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11e63b5b-a6de-4251-bb02-2731013ca5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d2432a51854de0b686814568d4c710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
    "\n",
    "model_path = 'models/mpnet_local'\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "   model = SentenceTransformer(model_path)\n",
    "\n",
    "else:\n",
    "  model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "  model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1145562-9dda-452a-a375-905ba0534b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sentence(text):\n",
    "  clean = re.sub(r'\\b([a-zA-Z]\\.),{2,}\\b|([0-9]+\\.(?!\\d))', lambda m: m.group().replace('.', '[DOT]'), text)\n",
    "  pattern = r'[\\.\\?\\!]\\s+'\n",
    "  match = re.split(pattern, clean)\n",
    "  sentence = []\n",
    "  for s in match:\n",
    "      s = s.replace('[DOT]', '.')\n",
    "      sentence.append(s)\n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f259461-1ac3-4a3b-b157-7e2b1ab4c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(text):\n",
    "  sentence_list = text_to_sentence(text)\n",
    "  sentence_vector = model.encode(\n",
    "                      sentence_list, \n",
    "                      output_value='sentence_embedding',\n",
    "                      convert_to_numpy=True,\n",
    "                      convert_to_tensor=False,\n",
    "                      batch_size=24,\n",
    "                      normalize_embeddings=True\n",
    "                    )\n",
    "  # print(sentence_vector)\n",
    "  # print(len(sentence_vector))\n",
    "\n",
    "  similarity = util.cos_sim(sentence_vector, sentence_vector)\n",
    "  print(similarity)\n",
    "  sns.heatmap(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f7c36-521f-43fc-9f86-6afae137219a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d0a5cb-7b1e-4815-bcb3-79e7fe44ec89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
